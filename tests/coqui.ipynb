{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TTS.api import TTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = './tts_output/tts.mp3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running a multi-speaker and multi-lingual model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No API token found for üê∏Coqui Studio voices - https://coqui.ai \n",
      "Visit üîóhttps://app.coqui.ai/account to get one.\n",
      "Set it as an environment variable `export COQUI_STUDIO_TOKEN=<token>`\n",
      "\n",
      " > tts_models/multilingual/multi-dataset/your_tts is already downloaded.\n",
      " > Using model: vits\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:16000\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:0\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:None\n",
      " | > fft_size:1024\n",
      " | > power:None\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:None\n",
      " | > signal_norm:None\n",
      " | > symmetric_norm:None\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:None\n",
      " | > pitch_fmin:None\n",
      " | > pitch_fmax:None\n",
      " | > spec_gain:20.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:1.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:False\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Model fully restored. \n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:16000\n",
      " | > resample:False\n",
      " | > num_mels:64\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:512\n",
      " | > power:1.5\n",
      " | > preemphasis:0.97\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:False\n",
      " | > symmetric_norm:False\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:8000.0\n",
      " | > pitch_fmin:1.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:20.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:False\n",
      " | > do_trim_silence:False\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:True\n",
      " | > db_level:-27.0\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:160\n",
      " | > win_length:400\n",
      " > External Speaker Encoder Loaded !!\n",
      " > initialization of language-embedding layers.\n",
      " > Model fully restored. \n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:16000\n",
      " | > resample:False\n",
      " | > num_mels:64\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:512\n",
      " | > power:1.5\n",
      " | > preemphasis:0.97\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:False\n",
      " | > symmetric_norm:False\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:8000.0\n",
      " | > pitch_fmin:1.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:20.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:False\n",
      " | > do_trim_silence:False\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:True\n",
      " | > db_level:-27.0\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:160\n",
      " | > win_length:400\n"
     ]
    }
   ],
   "source": [
    "# List available üê∏TTS models and choose the first one\n",
    "model_name = TTS.list_models()[0]\n",
    "# Init TTS\n",
    "tts = TTS(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run TTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Text splitted to sentences.\n",
      "['This is a test!', 'This is also a test!!']\n",
      " > Processing time: 0.866642951965332\n",
      " > Real-time factor: 0.19759301230399726\n",
      " > Text splitted to sentences.\n",
      "['Hello world!']\n",
      " > Processing time: 0.36327409744262695\n",
      " > Real-time factor: 0.23635269840118867\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'output.wav'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ‚ùó Since this model is multi-speaker and multi-lingual, we must set the target speaker and the language\n",
    "# Text to speech with a numpy output\n",
    "wav = tts.tts(\"This is a test! This is also a test!!\", speaker=tts.speakers[0], language=tts.languages[0])\n",
    "# Text to speech to a file\n",
    "tts.tts_to_file(text=\"Hello world!\", speaker=tts.speakers[0], language=tts.languages[0], file_path=\"output.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > tts_models/de/thorsten/tacotron2-DDC is already downloaded.\n",
      " > vocoder_models/de/thorsten/hifigan_v1 is already downloaded.\n",
      " > Using model: tacotron2\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:1024\n",
      " | > power:1.5\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:False\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:50.0\n",
      " | > mel_fmax:None\n",
      " | > pitch_fmin:0.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:1.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:True\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:2.718281828459045\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Model's reduction rate `r` is set to: 2\n",
      " > Vocoder Model: hifigan\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:1024\n",
      " | > power:1.5\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:False\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:50.0\n",
      " | > mel_fmax:None\n",
      " | > pitch_fmin:1.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:1.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:True\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:/home/g14/.local/share/tts/vocoder_models--de--thorsten--hifigan_v1/scale_stats.npy\n",
      " | > base:10\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Generator Model: hifigan_generator\n",
      " > Discriminator Model: hifigan_discriminator\n",
      "Removing weight norm...\n",
      " > Text splitted to sentences.\n",
      "['Ich bin eine Testnachricht.']\n",
      " > Processing time: 1.002823829650879\n",
      " > Real-time factor: 0.5232929156522595\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './tts_output/tts.mp3'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m tts \u001b[39m=\u001b[39m TTS(model_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtts_models/de/thorsten/tacotron2-DDC\u001b[39m\u001b[39m\"\u001b[39m, progress_bar\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, gpu\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m      5\u001b[0m \u001b[39m# Run TTS\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m tts\u001b[39m.\u001b[39;49mtts_to_file(text\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mIch bin eine Testnachricht.\u001b[39;49m\u001b[39m\"\u001b[39;49m, file_path\u001b[39m=\u001b[39;49mOUTPUT_PATH)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/TTS/api.py:597\u001b[0m, in \u001b[0;36mTTS.tts_to_file\u001b[0;34m(self, text, speaker, language, speaker_wav, emotion, speed, file_path, **kwargs)\u001b[0m\n\u001b[1;32m    593\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtts_coqui_studio(\n\u001b[1;32m    594\u001b[0m         text\u001b[39m=\u001b[39mtext, speaker_name\u001b[39m=\u001b[39mspeaker, language\u001b[39m=\u001b[39mlanguage, emotion\u001b[39m=\u001b[39memotion, speed\u001b[39m=\u001b[39mspeed, file_path\u001b[39m=\u001b[39mfile_path\n\u001b[1;32m    595\u001b[0m     )\n\u001b[1;32m    596\u001b[0m wav \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtts(text\u001b[39m=\u001b[39mtext, speaker\u001b[39m=\u001b[39mspeaker, language\u001b[39m=\u001b[39mlanguage, speaker_wav\u001b[39m=\u001b[39mspeaker_wav, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 597\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msynthesizer\u001b[39m.\u001b[39;49msave_wav(wav\u001b[39m=\u001b[39;49mwav, path\u001b[39m=\u001b[39;49mfile_path)\n\u001b[1;32m    598\u001b[0m \u001b[39mreturn\u001b[39;00m file_path\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/TTS/utils/synthesizer.py:244\u001b[0m, in \u001b[0;36mSynthesizer.save_wav\u001b[0;34m(self, wav, path)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Save the waveform as a file.\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \n\u001b[1;32m    239\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m    240\u001b[0m \u001b[39m    wav (List[int]): waveform as a list of values.\u001b[39;00m\n\u001b[1;32m    241\u001b[0m \u001b[39m    path (str): output path to save the waveform.\u001b[39;00m\n\u001b[1;32m    242\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    243\u001b[0m wav \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(wav)\n\u001b[0;32m--> 244\u001b[0m save_wav(wav\u001b[39m=\u001b[39;49mwav, path\u001b[39m=\u001b[39;49mpath, sample_rate\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moutput_sample_rate)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/TTS/utils/audio/numpy_transforms.py:439\u001b[0m, in \u001b[0;36msave_wav\u001b[0;34m(wav, path, sample_rate, **kwargs)\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Save float waveform to a file using Scipy.\u001b[39;00m\n\u001b[1;32m    432\u001b[0m \n\u001b[1;32m    433\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[39m    sr (int, optional): Sampling rate used for saving to the file. Defaults to None.\u001b[39;00m\n\u001b[1;32m    437\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    438\u001b[0m wav_norm \u001b[39m=\u001b[39m wav \u001b[39m*\u001b[39m (\u001b[39m32767\u001b[39m \u001b[39m/\u001b[39m \u001b[39mmax\u001b[39m(\u001b[39m0.01\u001b[39m, np\u001b[39m.\u001b[39mmax(np\u001b[39m.\u001b[39mabs(wav))))\n\u001b[0;32m--> 439\u001b[0m scipy\u001b[39m.\u001b[39;49mio\u001b[39m.\u001b[39;49mwavfile\u001b[39m.\u001b[39;49mwrite(path, sample_rate, wav_norm\u001b[39m.\u001b[39;49mastype(np\u001b[39m.\u001b[39;49mint16))\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/scipy/io/wavfile.py:767\u001b[0m, in \u001b[0;36mwrite\u001b[0;34m(filename, rate, data)\u001b[0m\n\u001b[1;32m    765\u001b[0m     fid \u001b[39m=\u001b[39m filename\n\u001b[1;32m    766\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 767\u001b[0m     fid \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(filename, \u001b[39m'\u001b[39;49m\u001b[39mwb\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m    769\u001b[0m fs \u001b[39m=\u001b[39m rate\n\u001b[1;32m    771\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './tts_output/tts.mp3'"
     ]
    }
   ],
   "source": [
    "# Running a single speaker model\n",
    "\n",
    "# Init TTS with the target model name\n",
    "tts = TTS(model_name=\"tts_models/de/thorsten/tacotron2-DDC\", progress_bar=False, gpu=False)\n",
    "# Run TTS\n",
    "tts.tts_to_file(text=\"Ich bin eine Testnachricht.\", file_path=OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > tts_models/multilingual/multi-dataset/your_tts is already downloaded.\n",
      " > Using model: vits\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:16000\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:0\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:None\n",
      " | > fft_size:1024\n",
      " | > power:None\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:None\n",
      " | > signal_norm:None\n",
      " | > symmetric_norm:None\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:None\n",
      " | > pitch_fmin:None\n",
      " | > pitch_fmax:None\n",
      " | > spec_gain:20.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:1.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:False\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Model fully restored. \n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:16000\n",
      " | > resample:False\n",
      " | > num_mels:64\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:512\n",
      " | > power:1.5\n",
      " | > preemphasis:0.97\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:False\n",
      " | > symmetric_norm:False\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:8000.0\n",
      " | > pitch_fmin:1.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:20.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:False\n",
      " | > do_trim_silence:False\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:True\n",
      " | > db_level:-27.0\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:160\n",
      " | > win_length:400\n",
      " > External Speaker Encoder Loaded !!\n",
      " > initialization of language-embedding layers.\n",
      " > Model fully restored. \n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:16000\n",
      " | > resample:False\n",
      " | > num_mels:64\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:512\n",
      " | > power:1.5\n",
      " | > preemphasis:0.97\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:False\n",
      " | > symmetric_norm:False\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:8000.0\n",
      " | > pitch_fmin:1.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:20.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:False\n",
      " | > do_trim_silence:False\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:True\n",
      " | > db_level:-27.0\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:160\n",
      " | > win_length:400\n",
      " > Text splitted to sentences.\n",
      "['This is voice cloning.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/g14/.local/lib/python3.9/site-packages/TTS/utils/audio/processor.py:684: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  x, sr = librosa.load(filename, sr=sr)\n",
      "/home/g14/.local/lib/python3.9/site-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'my/cloning/audio.wav'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLibsndfileError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/librosa/core/audio.py:176\u001b[0m, in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 176\u001b[0m     y, sr_native \u001b[39m=\u001b[39m __soundfile_load(path, offset, duration, dtype)\n\u001b[1;32m    178\u001b[0m \u001b[39mexcept\u001b[39;00m sf\u001b[39m.\u001b[39mSoundFileRuntimeError \u001b[39mas\u001b[39;00m exc:\n\u001b[1;32m    179\u001b[0m     \u001b[39m# If soundfile failed, try audioread instead\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/librosa/core/audio.py:209\u001b[0m, in \u001b[0;36m__soundfile_load\u001b[0;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[39m# Otherwise, create the soundfile object\u001b[39;00m\n\u001b[0;32m--> 209\u001b[0m     context \u001b[39m=\u001b[39m sf\u001b[39m.\u001b[39;49mSoundFile(path)\n\u001b[1;32m    211\u001b[0m \u001b[39mwith\u001b[39;00m context \u001b[39mas\u001b[39;00m sf_desc:\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/soundfile.py:658\u001b[0m, in \u001b[0;36mSoundFile.__init__\u001b[0;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd)\u001b[0m\n\u001b[1;32m    656\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_info \u001b[39m=\u001b[39m _create_info_struct(file, mode, samplerate, channels,\n\u001b[1;32m    657\u001b[0m                                  \u001b[39mformat\u001b[39m, subtype, endian)\n\u001b[0;32m--> 658\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_file \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_open(file, mode_int, closefd)\n\u001b[1;32m    659\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mset\u001b[39m(mode)\u001b[39m.\u001b[39missuperset(\u001b[39m'\u001b[39m\u001b[39mr+\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseekable():\n\u001b[1;32m    660\u001b[0m     \u001b[39m# Move write position to 0 (like in Python file objects)\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/soundfile.py:1216\u001b[0m, in \u001b[0;36mSoundFile._open\u001b[0;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[1;32m   1215\u001b[0m     err \u001b[39m=\u001b[39m _snd\u001b[39m.\u001b[39msf_error(file_ptr)\n\u001b[0;32m-> 1216\u001b[0m     \u001b[39mraise\u001b[39;00m LibsndfileError(err, prefix\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mError opening \u001b[39m\u001b[39m{0!r}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname))\n\u001b[1;32m   1217\u001b[0m \u001b[39mif\u001b[39;00m mode_int \u001b[39m==\u001b[39m _snd\u001b[39m.\u001b[39mSFM_WRITE:\n\u001b[1;32m   1218\u001b[0m     \u001b[39m# Due to a bug in libsndfile version <= 1.0.25, frames != 0\u001b[39;00m\n\u001b[1;32m   1219\u001b[0m     \u001b[39m# when opening a named pipe in SFM_WRITE mode.\u001b[39;00m\n\u001b[1;32m   1220\u001b[0m     \u001b[39m# See http://github.com/erikd/libsndfile/issues/77.\u001b[39;00m\n",
      "\u001b[0;31mLibsndfileError\u001b[0m: Error opening 'my/cloning/audio.wav': System error.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Example voice cloning with YourTTS in English, French and Portuguese\u001b[39;00m\n\u001b[1;32m      3\u001b[0m tts \u001b[39m=\u001b[39m TTS(model_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtts_models/multilingual/multi-dataset/your_tts\u001b[39m\u001b[39m\"\u001b[39m, progress_bar\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, gpu\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m----> 4\u001b[0m tts\u001b[39m.\u001b[39;49mtts_to_file(\u001b[39m\"\u001b[39;49m\u001b[39mThis is voice cloning.\u001b[39;49m\u001b[39m\"\u001b[39;49m, speaker_wav\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mmy/cloning/audio.wav\u001b[39;49m\u001b[39m\"\u001b[39;49m, language\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39men\u001b[39;49m\u001b[39m\"\u001b[39;49m, file_path\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39moutput.wav\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      5\u001b[0m tts\u001b[39m.\u001b[39mtts_to_file(\u001b[39m\"\u001b[39m\u001b[39mC\u001b[39m\u001b[39m'\u001b[39m\u001b[39mest le clonage de la voix.\u001b[39m\u001b[39m\"\u001b[39m, speaker_wav\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmy/cloning/audio.wav\u001b[39m\u001b[39m\"\u001b[39m, language\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfr-fr\u001b[39m\u001b[39m\"\u001b[39m, file_path\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39moutput.wav\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m tts\u001b[39m.\u001b[39mtts_to_file(\u001b[39m\"\u001b[39m\u001b[39mIsso √© clonagem de voz.\u001b[39m\u001b[39m\"\u001b[39m, speaker_wav\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmy/cloning/audio.wav\u001b[39m\u001b[39m\"\u001b[39m, language\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpt-br\u001b[39m\u001b[39m\"\u001b[39m, file_path\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39moutput.wav\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/TTS/api.py:596\u001b[0m, in \u001b[0;36mTTS.tts_to_file\u001b[0;34m(self, text, speaker, language, speaker_wav, emotion, speed, file_path, **kwargs)\u001b[0m\n\u001b[1;32m    592\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcsapi \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    593\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtts_coqui_studio(\n\u001b[1;32m    594\u001b[0m         text\u001b[39m=\u001b[39mtext, speaker_name\u001b[39m=\u001b[39mspeaker, language\u001b[39m=\u001b[39mlanguage, emotion\u001b[39m=\u001b[39memotion, speed\u001b[39m=\u001b[39mspeed, file_path\u001b[39m=\u001b[39mfile_path\n\u001b[1;32m    595\u001b[0m     )\n\u001b[0;32m--> 596\u001b[0m wav \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtts(text\u001b[39m=\u001b[39;49mtext, speaker\u001b[39m=\u001b[39;49mspeaker, language\u001b[39m=\u001b[39;49mlanguage, speaker_wav\u001b[39m=\u001b[39;49mspeaker_wav, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    597\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msynthesizer\u001b[39m.\u001b[39msave_wav(wav\u001b[39m=\u001b[39mwav, path\u001b[39m=\u001b[39mfile_path)\n\u001b[1;32m    598\u001b[0m \u001b[39mreturn\u001b[39;00m file_path\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/TTS/api.py:543\u001b[0m, in \u001b[0;36mTTS.tts\u001b[0;34m(self, text, speaker, language, speaker_wav, emotion, speed, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcsapi \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    540\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtts_coqui_studio(\n\u001b[1;32m    541\u001b[0m         text\u001b[39m=\u001b[39mtext, speaker_name\u001b[39m=\u001b[39mspeaker, language\u001b[39m=\u001b[39mlanguage, emotion\u001b[39m=\u001b[39memotion, speed\u001b[39m=\u001b[39mspeed\n\u001b[1;32m    542\u001b[0m     )\n\u001b[0;32m--> 543\u001b[0m wav \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msynthesizer\u001b[39m.\u001b[39;49mtts(\n\u001b[1;32m    544\u001b[0m     text\u001b[39m=\u001b[39;49mtext,\n\u001b[1;32m    545\u001b[0m     speaker_name\u001b[39m=\u001b[39;49mspeaker,\n\u001b[1;32m    546\u001b[0m     language_name\u001b[39m=\u001b[39;49mlanguage,\n\u001b[1;32m    547\u001b[0m     speaker_wav\u001b[39m=\u001b[39;49mspeaker_wav,\n\u001b[1;32m    548\u001b[0m     reference_wav\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    549\u001b[0m     style_wav\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    550\u001b[0m     style_text\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    551\u001b[0m     reference_speaker_name\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    552\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    553\u001b[0m )\n\u001b[1;32m    554\u001b[0m \u001b[39mreturn\u001b[39;00m wav\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/TTS/utils/synthesizer.py:357\u001b[0m, in \u001b[0;36mSynthesizer.tts\u001b[0;34m(self, text, speaker_name, language_name, speaker_wav, style_wav, style_text, reference_wav, reference_speaker_name, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[39m# compute a new d_vector from the given clip.\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[39mif\u001b[39;00m speaker_wav \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtts_model\u001b[39m.\u001b[39mspeaker_manager \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 357\u001b[0m     speaker_embedding \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtts_model\u001b[39m.\u001b[39;49mspeaker_manager\u001b[39m.\u001b[39;49mcompute_embedding_from_clip(speaker_wav)\n\u001b[1;32m    359\u001b[0m use_gl \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvocoder_model \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    361\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m reference_wav:  \u001b[39m# not voice conversion\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/TTS/tts/utils/managers.py:365\u001b[0m, in \u001b[0;36mEmbeddingManager.compute_embedding_from_clip\u001b[0;34m(self, wav_file)\u001b[0m\n\u001b[1;32m    363\u001b[0m             embeddings \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m embedding\n\u001b[1;32m    364\u001b[0m     \u001b[39mreturn\u001b[39;00m (embeddings \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(wav_file))[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mtolist()\n\u001b[0;32m--> 365\u001b[0m embedding \u001b[39m=\u001b[39m _compute(wav_file)\n\u001b[1;32m    366\u001b[0m \u001b[39mreturn\u001b[39;00m embedding[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mtolist()\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/TTS/tts/utils/managers.py:342\u001b[0m, in \u001b[0;36mEmbeddingManager.compute_embedding_from_clip.<locals>._compute\u001b[0;34m(wav_file)\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_compute\u001b[39m(wav_file: \u001b[39mstr\u001b[39m):\n\u001b[0;32m--> 342\u001b[0m     waveform \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder_ap\u001b[39m.\u001b[39;49mload_wav(wav_file, sr\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder_ap\u001b[39m.\u001b[39;49msample_rate)\n\u001b[1;32m    343\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder_config\u001b[39m.\u001b[39mmodel_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39muse_torch_spec\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    344\u001b[0m         m_input \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder_ap\u001b[39m.\u001b[39mmelspectrogram(waveform)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/TTS/utils/audio/processor.py:684\u001b[0m, in \u001b[0;36mAudioProcessor.load_wav\u001b[0;34m(self, filename, sr)\u001b[0m\n\u001b[1;32m    682\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msample_rate \u001b[39m==\u001b[39m sr, \u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m vs \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msample_rate, sr)\n\u001b[1;32m    683\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 684\u001b[0m     x, sr \u001b[39m=\u001b[39m librosa\u001b[39m.\u001b[39;49mload(filename, sr\u001b[39m=\u001b[39;49msr)\n\u001b[1;32m    685\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdo_trim_silence:\n\u001b[1;32m    686\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/librosa/core/audio.py:184\u001b[0m, in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(path, (\u001b[39mstr\u001b[39m, pathlib\u001b[39m.\u001b[39mPurePath)):\n\u001b[1;32m    181\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    182\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPySoundFile failed. Trying audioread instead.\u001b[39m\u001b[39m\"\u001b[39m, stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m\n\u001b[1;32m    183\u001b[0m     )\n\u001b[0;32m--> 184\u001b[0m     y, sr_native \u001b[39m=\u001b[39m __audioread_load(path, offset, duration, dtype)\n\u001b[1;32m    185\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    186\u001b[0m     \u001b[39mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/decorator.py:232\u001b[0m, in \u001b[0;36mdecorate.<locals>.fun\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m kwsyntax:\n\u001b[1;32m    231\u001b[0m     args, kw \u001b[39m=\u001b[39m fix(args, kw, sig)\n\u001b[0;32m--> 232\u001b[0m \u001b[39mreturn\u001b[39;00m caller(func, \u001b[39m*\u001b[39;49m(extras \u001b[39m+\u001b[39;49m args), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/librosa/util/decorators.py:60\u001b[0m, in \u001b[0;36mdeprecated.<locals>.__wrapper\u001b[0;34m(func, *args, **kwargs)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Warn the user, and then proceed.\"\"\"\u001b[39;00m\n\u001b[1;32m     52\u001b[0m warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m     53\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m{:s}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{:s}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39mDeprecated as of librosa version \u001b[39m\u001b[39m{:s}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     54\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39mIt will be removed in librosa version \u001b[39m\u001b[39m{:s}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     58\u001b[0m     stacklevel\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m,  \u001b[39m# Would be 2, but the decorator adds a level\u001b[39;00m\n\u001b[1;32m     59\u001b[0m )\n\u001b[0;32m---> 60\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/librosa/core/audio.py:241\u001b[0m, in \u001b[0;36m__audioread_load\u001b[0;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[1;32m    238\u001b[0m     reader \u001b[39m=\u001b[39m path\n\u001b[1;32m    239\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    240\u001b[0m     \u001b[39m# If the input was not an audioread object, try to open it\u001b[39;00m\n\u001b[0;32m--> 241\u001b[0m     reader \u001b[39m=\u001b[39m audioread\u001b[39m.\u001b[39;49maudio_open(path)\n\u001b[1;32m    243\u001b[0m \u001b[39mwith\u001b[39;00m reader \u001b[39mas\u001b[39;00m input_file:\n\u001b[1;32m    244\u001b[0m     sr_native \u001b[39m=\u001b[39m input_file\u001b[39m.\u001b[39msamplerate\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/audioread/__init__.py:127\u001b[0m, in \u001b[0;36maudio_open\u001b[0;34m(path, backends)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[39mfor\u001b[39;00m BackendClass \u001b[39min\u001b[39;00m backends:\n\u001b[1;32m    126\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 127\u001b[0m         \u001b[39mreturn\u001b[39;00m BackendClass(path)\n\u001b[1;32m    128\u001b[0m     \u001b[39mexcept\u001b[39;00m DecodeError:\n\u001b[1;32m    129\u001b[0m         \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/audioread/rawread.py:59\u001b[0m, in \u001b[0;36mRawAudioFile.__init__\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, filename):\n\u001b[0;32m---> 59\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fh \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(filename, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     61\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_file \u001b[39m=\u001b[39m aifc\u001b[39m.\u001b[39mopen(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fh)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'my/cloning/audio.wav'"
     ]
    }
   ],
   "source": [
    "# Example voice cloning with YourTTS in English, French and Portuguese\n",
    "\n",
    "tts = TTS(model_name=\"tts_models/multilingual/multi-dataset/your_tts\", progress_bar=False, gpu=True)\n",
    "tts.tts_to_file(\"This is voice cloning.\", speaker_wav=\"my/cloning/audio.wav\", language=\"en\", file_path=\"output.wav\")\n",
    "tts.tts_to_file(\"C'est le clonage de la voix.\", speaker_wav=\"my/cloning/audio.wav\", language=\"fr-fr\", file_path=\"output.wav\")\n",
    "tts.tts_to_file(\"Isso √© clonagem de voz.\", speaker_wav=\"my/cloning/audio.wav\", language=\"pt-br\", file_path=\"output.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Downloading model to /home/g14/.local/share/tts/voice_conversion_models--multilingual--vctk--freevc24\n",
      " > Model's license - MIT\n",
      " > Check https://choosealicense.com/licenses/mit/ for more info.\n",
      " > Using model: freevc\n",
      " > Loading pretrained speaker encoder model ...\n",
      "Loaded the voice encoder model on cuda in 589.93 seconds.\n",
      " > Downloading WavLM model to /home/g14/.local/share/tts/wavlm/WavLM-Large.pt ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/g14/.local/lib/python3.9/site-packages/TTS/vc/models/freevc.py:625: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  wav, _ = librosa.load(wav, sr=self.config.audio.input_sample_rate)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'my/target.wav'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLibsndfileError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/librosa/core/audio.py:176\u001b[0m, in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 176\u001b[0m     y, sr_native \u001b[39m=\u001b[39m __soundfile_load(path, offset, duration, dtype)\n\u001b[1;32m    178\u001b[0m \u001b[39mexcept\u001b[39;00m sf\u001b[39m.\u001b[39mSoundFileRuntimeError \u001b[39mas\u001b[39;00m exc:\n\u001b[1;32m    179\u001b[0m     \u001b[39m# If soundfile failed, try audioread instead\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/librosa/core/audio.py:209\u001b[0m, in \u001b[0;36m__soundfile_load\u001b[0;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[39m# Otherwise, create the soundfile object\u001b[39;00m\n\u001b[0;32m--> 209\u001b[0m     context \u001b[39m=\u001b[39m sf\u001b[39m.\u001b[39;49mSoundFile(path)\n\u001b[1;32m    211\u001b[0m \u001b[39mwith\u001b[39;00m context \u001b[39mas\u001b[39;00m sf_desc:\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/soundfile.py:658\u001b[0m, in \u001b[0;36mSoundFile.__init__\u001b[0;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd)\u001b[0m\n\u001b[1;32m    656\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_info \u001b[39m=\u001b[39m _create_info_struct(file, mode, samplerate, channels,\n\u001b[1;32m    657\u001b[0m                                  \u001b[39mformat\u001b[39m, subtype, endian)\n\u001b[0;32m--> 658\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_file \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_open(file, mode_int, closefd)\n\u001b[1;32m    659\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mset\u001b[39m(mode)\u001b[39m.\u001b[39missuperset(\u001b[39m'\u001b[39m\u001b[39mr+\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseekable():\n\u001b[1;32m    660\u001b[0m     \u001b[39m# Move write position to 0 (like in Python file objects)\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/soundfile.py:1216\u001b[0m, in \u001b[0;36mSoundFile._open\u001b[0;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[1;32m   1215\u001b[0m     err \u001b[39m=\u001b[39m _snd\u001b[39m.\u001b[39msf_error(file_ptr)\n\u001b[0;32m-> 1216\u001b[0m     \u001b[39mraise\u001b[39;00m LibsndfileError(err, prefix\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mError opening \u001b[39m\u001b[39m{0!r}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname))\n\u001b[1;32m   1217\u001b[0m \u001b[39mif\u001b[39;00m mode_int \u001b[39m==\u001b[39m _snd\u001b[39m.\u001b[39mSFM_WRITE:\n\u001b[1;32m   1218\u001b[0m     \u001b[39m# Due to a bug in libsndfile version <= 1.0.25, frames != 0\u001b[39;00m\n\u001b[1;32m   1219\u001b[0m     \u001b[39m# when opening a named pipe in SFM_WRITE mode.\u001b[39;00m\n\u001b[1;32m   1220\u001b[0m     \u001b[39m# See http://github.com/erikd/libsndfile/issues/77.\u001b[39;00m\n",
      "\u001b[0;31mLibsndfileError\u001b[0m: Error opening 'my/target.wav': System error.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Example voice conversion converting speaker of the `source_wav` to the speaker of the `target_wav`\u001b[39;00m\n\u001b[1;32m      3\u001b[0m tts \u001b[39m=\u001b[39m TTS(model_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mvoice_conversion_models/multilingual/vctk/freevc24\u001b[39m\u001b[39m\"\u001b[39m, progress_bar\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, gpu\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m----> 4\u001b[0m tts\u001b[39m.\u001b[39;49mvoice_conversion_to_file(source_wav\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mmy/source.wav\u001b[39;49m\u001b[39m\"\u001b[39;49m, target_wav\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mmy/target.wav\u001b[39;49m\u001b[39m\"\u001b[39;49m, file_path\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39moutput.wav\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/TTS/api.py:632\u001b[0m, in \u001b[0;36mTTS.voice_conversion_to_file\u001b[0;34m(self, source_wav, target_wav, file_path)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvoice_conversion_to_file\u001b[39m(\n\u001b[1;32m    617\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    618\u001b[0m     source_wav: \u001b[39mstr\u001b[39m,\n\u001b[1;32m    619\u001b[0m     target_wav: \u001b[39mstr\u001b[39m,\n\u001b[1;32m    620\u001b[0m     file_path: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39moutput.wav\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    621\u001b[0m ):\n\u001b[1;32m    622\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Voice conversion with FreeVC. Convert source wav to target speaker.\u001b[39;00m\n\u001b[1;32m    623\u001b[0m \n\u001b[1;32m    624\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[39m            Output file path. Defaults to \"output.wav\".\u001b[39;00m\n\u001b[1;32m    631\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 632\u001b[0m     wav \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvoice_conversion(source_wav\u001b[39m=\u001b[39;49msource_wav, target_wav\u001b[39m=\u001b[39;49mtarget_wav)\n\u001b[1;32m    633\u001b[0m     save_wav(wav\u001b[39m=\u001b[39mwav, path\u001b[39m=\u001b[39mfile_path, sample_rate\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvoice_converter\u001b[39m.\u001b[39mvc_config\u001b[39m.\u001b[39maudio\u001b[39m.\u001b[39moutput_sample_rate)\n\u001b[1;32m    634\u001b[0m     \u001b[39mreturn\u001b[39;00m file_path\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/TTS/api.py:613\u001b[0m, in \u001b[0;36mTTS.voice_conversion\u001b[0;34m(self, source_wav, target_wav)\u001b[0m\n\u001b[1;32m    600\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvoice_conversion\u001b[39m(\n\u001b[1;32m    601\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    602\u001b[0m     source_wav: \u001b[39mstr\u001b[39m,\n\u001b[1;32m    603\u001b[0m     target_wav: \u001b[39mstr\u001b[39m,\n\u001b[1;32m    604\u001b[0m ):\n\u001b[1;32m    605\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Voice conversion with FreeVC. Convert source wav to target speaker.\u001b[39;00m\n\u001b[1;32m    606\u001b[0m \n\u001b[1;32m    607\u001b[0m \u001b[39m    Args:``\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[39m            Path to the target wav file.\u001b[39;00m\n\u001b[1;32m    612\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 613\u001b[0m     wav \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvoice_converter\u001b[39m.\u001b[39;49mvoice_conversion(source_wav\u001b[39m=\u001b[39;49msource_wav, target_wav\u001b[39m=\u001b[39;49mtarget_wav)\n\u001b[1;32m    614\u001b[0m     \u001b[39mreturn\u001b[39;00m wav\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/TTS/utils/synthesizer.py:247\u001b[0m, in \u001b[0;36mSynthesizer.voice_conversion\u001b[0;34m(self, source_wav, target_wav)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvoice_conversion\u001b[39m(\u001b[39mself\u001b[39m, source_wav: \u001b[39mstr\u001b[39m, target_wav: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[\u001b[39mint\u001b[39m]:\n\u001b[0;32m--> 247\u001b[0m     output_wav \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvc_model\u001b[39m.\u001b[39;49mvoice_conversion(source_wav, target_wav)\n\u001b[1;32m    248\u001b[0m     \u001b[39mreturn\u001b[39;00m output_wav\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/TTS/vc/models/freevc.py:647\u001b[0m, in \u001b[0;36mFreeVC.voice_conversion\u001b[0;34m(self, src, tgt)\u001b[0m\n\u001b[1;32m    634\u001b[0m \u001b[39m@torch\u001b[39m\u001b[39m.\u001b[39minference_mode()\n\u001b[1;32m    635\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvoice_conversion\u001b[39m(\u001b[39mself\u001b[39m, src, tgt):\n\u001b[1;32m    636\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    637\u001b[0m \u001b[39m    Voice conversion pass of the model.\u001b[39;00m\n\u001b[1;32m    638\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    644\u001b[0m \u001b[39m        torch.Tensor: Output tensor.\u001b[39;00m\n\u001b[1;32m    645\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 647\u001b[0m     wav_tgt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mload_audio(tgt)\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()\n\u001b[1;32m    648\u001b[0m     wav_tgt, _ \u001b[39m=\u001b[39m librosa\u001b[39m.\u001b[39meffects\u001b[39m.\u001b[39mtrim(wav_tgt, top_db\u001b[39m=\u001b[39m\u001b[39m20\u001b[39m)\n\u001b[1;32m    650\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mmodel_args\u001b[39m.\u001b[39muse_spk:\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/TTS/vc/models/freevc.py:625\u001b[0m, in \u001b[0;36mFreeVC.load_audio\u001b[0;34m(self, wav)\u001b[0m\n\u001b[1;32m    623\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Read and format the input audio.\"\"\"\u001b[39;00m\n\u001b[1;32m    624\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(wav, \u001b[39mstr\u001b[39m):\n\u001b[0;32m--> 625\u001b[0m     wav, _ \u001b[39m=\u001b[39m librosa\u001b[39m.\u001b[39;49mload(wav, sr\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig\u001b[39m.\u001b[39;49maudio\u001b[39m.\u001b[39;49minput_sample_rate)\n\u001b[1;32m    626\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(wav, np\u001b[39m.\u001b[39mndarray):\n\u001b[1;32m    627\u001b[0m     wav \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mfrom_numpy(wav)\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/librosa/core/audio.py:184\u001b[0m, in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(path, (\u001b[39mstr\u001b[39m, pathlib\u001b[39m.\u001b[39mPurePath)):\n\u001b[1;32m    181\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    182\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPySoundFile failed. Trying audioread instead.\u001b[39m\u001b[39m\"\u001b[39m, stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m\n\u001b[1;32m    183\u001b[0m     )\n\u001b[0;32m--> 184\u001b[0m     y, sr_native \u001b[39m=\u001b[39m __audioread_load(path, offset, duration, dtype)\n\u001b[1;32m    185\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    186\u001b[0m     \u001b[39mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/decorator.py:232\u001b[0m, in \u001b[0;36mdecorate.<locals>.fun\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m kwsyntax:\n\u001b[1;32m    231\u001b[0m     args, kw \u001b[39m=\u001b[39m fix(args, kw, sig)\n\u001b[0;32m--> 232\u001b[0m \u001b[39mreturn\u001b[39;00m caller(func, \u001b[39m*\u001b[39;49m(extras \u001b[39m+\u001b[39;49m args), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/librosa/util/decorators.py:60\u001b[0m, in \u001b[0;36mdeprecated.<locals>.__wrapper\u001b[0;34m(func, *args, **kwargs)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Warn the user, and then proceed.\"\"\"\u001b[39;00m\n\u001b[1;32m     52\u001b[0m warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m     53\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m{:s}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{:s}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39mDeprecated as of librosa version \u001b[39m\u001b[39m{:s}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     54\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39mIt will be removed in librosa version \u001b[39m\u001b[39m{:s}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     58\u001b[0m     stacklevel\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m,  \u001b[39m# Would be 2, but the decorator adds a level\u001b[39;00m\n\u001b[1;32m     59\u001b[0m )\n\u001b[0;32m---> 60\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/librosa/core/audio.py:241\u001b[0m, in \u001b[0;36m__audioread_load\u001b[0;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[1;32m    238\u001b[0m     reader \u001b[39m=\u001b[39m path\n\u001b[1;32m    239\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    240\u001b[0m     \u001b[39m# If the input was not an audioread object, try to open it\u001b[39;00m\n\u001b[0;32m--> 241\u001b[0m     reader \u001b[39m=\u001b[39m audioread\u001b[39m.\u001b[39;49maudio_open(path)\n\u001b[1;32m    243\u001b[0m \u001b[39mwith\u001b[39;00m reader \u001b[39mas\u001b[39;00m input_file:\n\u001b[1;32m    244\u001b[0m     sr_native \u001b[39m=\u001b[39m input_file\u001b[39m.\u001b[39msamplerate\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/audioread/__init__.py:127\u001b[0m, in \u001b[0;36maudio_open\u001b[0;34m(path, backends)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[39mfor\u001b[39;00m BackendClass \u001b[39min\u001b[39;00m backends:\n\u001b[1;32m    126\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 127\u001b[0m         \u001b[39mreturn\u001b[39;00m BackendClass(path)\n\u001b[1;32m    128\u001b[0m     \u001b[39mexcept\u001b[39;00m DecodeError:\n\u001b[1;32m    129\u001b[0m         \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/audioread/rawread.py:59\u001b[0m, in \u001b[0;36mRawAudioFile.__init__\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, filename):\n\u001b[0;32m---> 59\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fh \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(filename, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     61\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_file \u001b[39m=\u001b[39m aifc\u001b[39m.\u001b[39mopen(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fh)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'my/target.wav'"
     ]
    }
   ],
   "source": [
    "# Example voice conversion converting speaker of the `source_wav` to the speaker of the `target_wav`\n",
    "\n",
    "tts = TTS(model_name=\"voice_conversion_models/multilingual/vctk/freevc24\", progress_bar=False, gpu=True)\n",
    "tts.voice_conversion_to_file(source_wav=\"my/source.wav\", target_wav=\"my/target.wav\", file_path=\"output.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example voice cloning by a single speaker TTS model combining with the voice conversion model. This way, you can\n",
    "# clone voices by using any model in üê∏TTS.\n",
    "\n",
    "tts = TTS(\"tts_models/de/thorsten/tacotron2-DDC\")\n",
    "tts.tts_with_vc_to_file(\n",
    "    \"Wie sage ich auf Italienisch, dass ich dich liebe?\",\n",
    "    speaker_wav=\"target/speaker.wav\",\n",
    "    file_path=\"output.wav\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example text to speech using [üê∏Coqui Studio](https://coqui.ai) models.\n",
    "\n",
    "# You can use all of your available speakers in the studio.\n",
    "# [üê∏Coqui Studio](https://coqui.ai) API token is required. You can get it from the [account page](https://coqui.ai/account).\n",
    "# You should set the `COQUI_STUDIO_TOKEN` environment variable to use the API token.\n",
    "\n",
    "# If you have a valid API token set you will see the studio speakers as separate models in the list.\n",
    "# The name format is coqui_studio/en/<studio_speaker_name>/coqui_studio\n",
    "models = TTS().list_models()\n",
    "# Init TTS with the target studio speaker\n",
    "tts = TTS(model_name=\"coqui_studio/en/Torcull Diarmuid/coqui_studio\", progress_bar=False, gpu=False)\n",
    "# Run TTS\n",
    "tts.tts_to_file(text=\"This is a test.\", file_path=OUTPUT_PATH)\n",
    "# Run TTS with emotion and speed control\n",
    "tts.tts_to_file(text=\"This is a test.\", file_path=OUTPUT_PATH, emotion=\"Happy\", speed=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example text to speech using **Fairseq models in ~1100 languages** ü§Ø.\n",
    "\n",
    "#For these models use the following name format: `tts_models/<lang-iso_code>/fairseq/vits`.\n",
    "#You can find the list of language ISO codes [here](https://dl.fbaipublicfiles.com/mms/tts/all-tts-languages.html) and learn about the Fairseq models [here](https://github.com/facebookresearch/fairseq/tree/main/examples/mms).\n",
    "\n",
    "# TTS with on the fly voice conversion\n",
    "api = TTS(\"tts_models/deu/fairseq/vits\")\n",
    "api.tts_with_vc_to_file(\n",
    "    \"Wie sage ich auf Italienisch, dass ich dich liebe?\",\n",
    "    speaker_wav=\"target/speaker.wav\",\n",
    "    file_path=\"output.wav\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
